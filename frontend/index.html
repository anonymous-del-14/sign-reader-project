<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Indian Language Image Translator — Sign Reader</title>

  <link rel="stylesheet" href="style.css">
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700&family=Poppins:wght@400;700&display=swap" rel="stylesheet">
  <!-- Font Awesome (icons) -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css" integrity="sha512-..." crossorigin="anonymous" referrerpolicy="no-referrer" />
  <header class="hero">
  <div class="hero-left">
    <h1><i class="fa-solid fa-camera-retro"></i> SnapToScript</h1>
    <p class="hint">Snap and translate — lightning fast.</p>
  </div>
  <img src="https://images.unsplash.com/photo-1706403615881-d83dc2067c5d?w=600&auto=format&fit=crop&q=60&ixlib=rb-4.1.0&ixid=M3wxMjA3fDB8MHxzZWFyY2h8Mnx8cGhvdG9zJTIwb2YlMjBpbmRpYW4lMjBsYW5ndWFnZXN8ZW58MHx8MHx8fDA%3D-...&auto=format&fit=crop&w=800&q=60" alt="hero" class="hero-image">
</header>
  
</head>
<body>
  <div class="container">
    <h1>Indian Language Image Translator — Sign Reader</h1>
    <p class="hint">Take a photo or choose an image of sign/text. We'll extract text (OCR) and translate to Hindi & English.</p>
    
    <div class="card">
      <div class="camera-area">
        <div>
          <video id="video" autoplay playsinline hidden></video>
          <canvas id="canvas" hidden></canvas>
          <img id="preview" alt="preview" />
        </div>

        <div style="flex:1;min-width:220px">
          <div class="controls">
            <button id="startBtn" class="btn">Start Camera</button>
            <button id="stopBtn" class="btn secondary">Stop Camera</button>
            <button id="snapBtn" class="btn primary">Capture & Translate</button>

            <label class="file-label">
              <input id="fileInput" type="file" accept="image/*" capture="environment" />
              <span class="btn ghost">Choose Photo</span>
            </label>
          </div>

          <div class="options">
            <label>Target:
              <select id="target">
                <option value="both">Hindi & English</option>
                <option value="en">English only</option>
                <option value="hi">Hindi only</option>
                <option value="fr">French</option>
                <option value="es">Spanish</option>
              </select>
            </label>

            <label style="margin-left:auto">
              <input id="autoUpload" type="checkbox" checked /> <span class="small muted">Auto-upload after capture/choose</span>
            </label>
          </div>

          <div id="status" class="status">Idle</div>
        </div>
      </div>
    </div>

    <div class="card">
      <h3>Extracted Text</h3>
      <textarea id="originalText" rows="4" placeholder="OCR result will appear here..."></textarea>
      <div style="margin-top:10px;display:flex;gap:8px;">
        <button id="manualUploadBtn" class="btn">Upload Current Image (OCR)</button>
        <button id="translateBtn" class="btn secondary">Translate Text</button>
        <button id="clearBtn" class="btn ghost">Clear</button>
      </div>
    </div>

    <div class="row">
      <div class="col card">
        <h3>Hindi Translation</h3>
        <textarea id="hindiText" rows="5" placeholder="Hindi translation..."></textarea>
      </div>
      <div class="col card">
        <h3>English Translation</h3>
        <textarea id="englishText" rows="5" placeholder="English translation..."></textarea>
      </div>
    </div>

    <footer class="footer">Tip: allow camera access. Runs best via HTTPS or on localhost. Backend endpoints expected at <code>/ocr</code> and <code>/translate</code> on the configured BACKEND_URL.</footer>
  </div>
  
  <script>
    // Adjust this to your backend base URL (including protocol and port if needed).
    // Example: 'http://localhost:5000' or 'https://api.example.com'
    const BACKEND_URL = 'http://localhost:5000';

    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const preview = document.getElementById('preview');
    const startBtn = document.getElementById('startBtn');
    const stopBtn = document.getElementById('stopBtn');
    const snapBtn = document.getElementById('snapBtn');
    const fileInput = document.getElementById('fileInput');
    const statusEl = document.getElementById('status');
    const autoUpload = document.getElementById('autoUpload');

    const originalTextEl = document.getElementById('originalText');
    const hindiTextEl = document.getElementById('hindiText');
    const englishTextEl = document.getElementById('englishText');

    const manualUploadBtn = document.getElementById('manualUploadBtn');
    const translateBtn = document.getElementById('translateBtn');
    const clearBtn = document.getElementById('clearBtn');
    const targetEl = document.getElementById('target');

    let stream = null;
    let lastBlob = null;

    function setStatus(s){
      statusEl.textContent = s;
    }
    // Ask permission BEFORE starting the camera
async function requestCameraPermission() {
  try {
    const permission = await navigator.permissions.query({ name: "camera" });

    if (permission.state === "denied") {
      alert("Camera access is blocked. Please enable it in your browser/app settings.");
      return false;
    }

    if (permission.state === "prompt") {
      // Trigger actual camera access request popup
      try {
        await navigator.mediaDevices.getUserMedia({ video: true });
      } catch (err) {
        alert("Please allow camera access to continue.");
        return false;
      }
    }

    return true;
  } catch (err) {
    // If Permissions API not supported (iPhone, some browsers)
    return true;
  }
}


    async function startCamera(){
  const ok = await requestCameraPermission();
  if (!ok) return;

  try{
    stream = await navigator.mediaDevices.getUserMedia({ 
      video: { facingMode: 'environment' }, 
      audio: false 
    });

    video.srcObject = stream;
    video.hidden = false;
    preview.hidden = true;
    setStatus('Camera started');

  } catch(err){
    console.error(err);
    alert("Camera error: " + (err.message || err));
    setStatus('Camera error: ' + (err.message || err));
  }
}


    function stopCamera(){
      if(stream){
        stream.getTracks().forEach(t => t.stop());
        stream = null;
      }
      video.srcObject = null;
      video.hidden = true;
      setStatus('Camera stopped');
    }

    function captureToPreview(){
      const w = video.videoWidth || 1280;
      const h = video.videoHeight || 720;
      canvas.width = w;
      canvas.height = h;
      const ctx = canvas.getContext('2d');
      ctx.drawImage(video, 0, 0, w, h);
      canvas.toBlob(blob => {
        lastBlob = blob;
        preview.src = URL.createObjectURL(blob);
        preview.hidden = false;
        video.hidden = true;
        setStatus('Captured image ready');
        if(autoUpload.checked) uploadBlobForOCR(blob);
      }, 'image/jpeg', 0.92);
    }

    function handleFileSelect(e){
      const file = e.target.files && e.target.files[0];
      if(!file) return;
      lastBlob = file;
      preview.src = URL.createObjectURL(file);
      preview.hidden = false;
      video.hidden = true;
      setStatus('Image chosen');
      if(autoUpload.checked) uploadBlobForOCR(file);
    }

    async function uploadBlobForOCR(blob){
      try{
        setStatus('Uploading image to OCR...');
        const fd = new FormData();
        fd.append('image', blob, 'photo.jpg');
        // optional: include target if your backend uses it
        fd.append('target', (targetEl.value === 'both' ? 'en' : targetEl.value) );

        const res = await fetch(`${BACKEND_URL}/api/translate`, {
          method: 'POST',
          body: fd
        });

        // always read as text first so we can log HTML errors
        const raw = await res.text();

        if (!res.ok) {
          console.error('Server returned non-OK status:', res.status, raw);
          setStatus('OCR server error: ' + res.status);
          return;
        }

        // try to parse JSON; if server returned HTML we'll log it
        let data;
        try {
          data = JSON.parse(raw);
        } catch (e) {
          console.error('Server returned non-JSON response for OCR:', raw);
          setStatus('OCR error: server returned unexpected response (see console)');
          return;
        }

        // Normalize possible response shapes:
        // - { originalText: "...", translatedText: "..." }
        // - { text: "...", result: "..." }
        // - { originalText: "...", detectedLanguage: "...", translatedText: {...} }
        const ocrText = data.originalText || data.text || data.result || data?.ocrText || '';
        originalTextEl.value = ocrText;

        setStatus('OCR complete');

        // Auto-translate if the target selection asked for it
        if (ocrText && targetEl.value) {
          autoTranslateAfterOCR();
        }
      } catch(err){
        console.error('uploadBlobForOCR error', err);
        setStatus('OCR error: ' + (err.message || String(err)));
      }
    }


    async function translateText(text, targets){
      try{
        setStatus('Translating...');
        const body = { text, targets };
        const res = await fetch(`${BACKEND_URL}/translate`, {
          method:'POST',
          headers:{ 'Content-Type':'application/json' },
          body: JSON.stringify(body)
        });
        if(!res.ok) throw new Error('Translate request failed: ' + res.status);
        const data = await res.json();
        setStatus('Translation complete');
        return data; // expect something like { hi: "...", en: "...", fr: "..."}
      } catch(err){
        console.error(err);
        setStatus('Translate error: ' + (err.message || err));
        return null;
      }
    }

    async function autoTranslateAfterOCR(){
      const txt = originalTextEl.value.trim();
      if(!txt) return;
      const t = targetEl.value;
      let targets = [];
      if(t === 'both') targets = ['hi','en'];
      else targets = [t];
      const res = await translateText(txt, targets);
      if(!res) return;
      // fill fields if present
      if(res.hi !== undefined) hindiTextEl.value = res.hi;
      if(res.en !== undefined) englishTextEl.value = res.en;
      // sometimes backend returns keyed by target language
      if(t !== 'both' && res[targetEl.value] !== undefined){
        if(targetEl.value === 'hi') hindiTextEl.value = res[targetEl.value];
        else if(targetEl.value === 'en') englishTextEl.value = res[targetEl.value];
      }
    }

    // Manual handlers
    startBtn.addEventListener('click', startCamera);
    stopBtn.addEventListener('click', stopCamera);
    snapBtn.addEventListener('click', () => {
      if(stream) captureToPreview();
      else {
        // if camera not running, but we have preview, just upload
        if(lastBlob) {
          uploadBlobForOCR(lastBlob);
        } else {
          setStatus('No camera or image available');
        }
      }
    });
    fileInput.addEventListener('change', handleFileSelect);
    manualUploadBtn.addEventListener('click', () => {
      if(!lastBlob){
        setStatus('Choose or capture an image first');
        return;
      }
      uploadBlobForOCR(lastBlob);
    });

    translateBtn.addEventListener('click', async () => {
      const txt = originalTextEl.value.trim();
      if(!txt){ setStatus('No text to translate'); return; }
      const t = targetEl.value;
      let targets = (t === 'both') ? ['hi','en'] : [t];
      const res = await translateText(txt, targets);
      if(!res) return;
      if(res.hi !== undefined) hindiTextEl.value = res.hi;
      if(res.en !== undefined) englishTextEl.value = res.en;
      if(targets.length===1){
        const key = targets[0];
        if(key === 'hi') hindiTextEl.value = res[key] ?? '';
        if(key === 'en') englishTextEl.value = res[key] ?? '';
      }
    });

    clearBtn.addEventListener('click', () => {
      originalTextEl.value='';
      hindiTextEl.value='';
      englishTextEl.value='';
      preview.src='';
      preview.hidden=true;
      lastBlob=null;
      setStatus('Cleared');
    });

    // convenience: allow paste of image into page
    window.addEventListener('paste', (e) => {
      const items = (e.clipboardData || e.originalEvent.clipboardData).items;
      for(const it of items){
        if(it.type.indexOf('image') === 0){
          const blob = it.getAsFile();
          lastBlob = blob;
          preview.src = URL.createObjectURL(blob);
          preview.hidden = false;
          video.hidden = true;
          setStatus('Pasted image');
          if(autoUpload.checked) uploadBlobForOCR(blob);
        }
      }
    });
  </script>
</body>
</html>